\chapter{Discussion}
\label{c:discussion}

\section{Performance Evaluation}
Perscheid et al. already have shown that the step-wise run-time analysis approach that serves as a basis of \textsc{PathObjects} enables the immediate exploration of a programs run-time while maintaining a low memory footprint  \cite{perscheid_immediacy_2010}.
To ensure that the computational extra work required for visualizing recorded object interactions preserves the immediate character of this approach, an evaluation of the runtime performance of our implementation is given in Section \ref{s:runtime-performance}.
Since \textsc{PathObjects} also introduces additional tracing effort, an analysis of its memory requirements is presented in Section \ref{s:space-consumption}.

\subsection{Runtime Performance}
\label{s:runtime-performance}
The major bottleneck in our approach of the rendering of object interactions can be accounted for by the hierarchical graph drawing that is performed during the visualization phase.
\todo{point out seq triv.}
Although the applied algorithm has been designed with its interactive application in mind and generally performs fast enough therefor \cite{gansner_technique_1993}, its runtime is heavily dependent on the specific structure of the graph at hand.
Precisely, the edge crossing minimization problem is NP-hard and the applied heuristic requires quadratic time in the number of nodes in the worst case \cite{tamassia_handbook_2013}, which eventuates when edges span the maximum possible number of ranks.
An example graph with $n$ ranks that shows this characteristic is depicted in Figure \ref{fig:graph-worst-case}.
Since it is practically impossible to predict to which degree call trees of test cases conform to this structure, an empirical study has been carried out with real-world software systems to examine the runtime behavior of our approach.

\begin{figure}[tb]
	\centering	
	\digraph
	[scale=1.0]{worstCaseRuntimeComplexity}
	{
		margin=0
		nodesep=0.4
		node [style=rounded, shape=box, fontsize=11, height=0.4]
		n1 [label=<N<SUB>1</SUB>>]
		n2 [label=<N<SUB>2</SUB>>]
		nx [label="...", style="rounded,dotted"]
		nn1 [label=<N<SUB>n-1</SUB>>]
		nn [label=<N<SUB>n</SUB>>]
		n1->n2
		n2 -> nx [style=dotted,arrowhead=onormal]
		nx->nn1 [style=dotted,arrowhead=onormal]
		nx -> nn [style=dotted, arrowhead=onormal]
		nn1-> nn
		n1 -> nn
		n2 -> nn
		{rank=same n1 n2 nx nn1 nn}
	}
	\caption{Example graph that entails the worst case runtime complexity of $\mathcal O(n^2)$.}
	\label{fig:graph-worst-case}
\end{figure}

\paragraph{Test Arrangement}
Bla blubb foo.

\paragraph{Test Environment} All measurements have been performed on an Intel\copyright{} Core\texttrademark{}  i7-2620M CPU @ 2.70GHz.
The Squeak image version 4.4-12327 has been executed with the Croquet Closure Stack VM, version StackInterpreter VMMaker-oscog-EstebanLorenzano.237\footnote{http://source.squeak.org/VMMaker/VMMaker-oscog-EstebanLorenzano.237.mcz, last checked \today}. This combination of CPU and VM performs at 528.1 million bytecodes/sec and 27.3 million sends/sec in the Squeak Tiny Benchmarks. Graphviz has been available in version 2.34.

\paragraph{Results}

\begin{figure}[b!]
	\centering
	\begin{gnuplot}[terminal=pdf, terminaloptions={enhanced font 'Verdana,12' 
	size 6in, 3in}]	
		set style line 1 linecolor rgb '#0060ad' lt 1 lw 3
		set style line 2 lc rgb '#0060ad' pt 9 ps 1 lt 1 lw 3
		set style line 3 lc rgb '#5e9c36' pt 7 ps 1 lt 1 lw 3
		set style line 11 lc rgb '#808080' lt 1 lw 5
		set border 3 back ls 11
		set tics nomirror
		set style line 12 lc rgb '#808080' lt 0 lw 1
		
		set grid back ls 12
		#set grid mxtics mytics ls 12
		
		#set ytics mirror
		set macros
		
		set xrange [50:100]
		set yrange [1:100]
		set logscale y 10
		
		# MACROS
		# x- and ytics for each row resp. column
		NOXTICS = "set xtics (60, 70, 80, 90); unset xlabel"
		NOYTICS = "set ytics format ' '; unset ylabel"
		# Margins for each row resp. column

		# Placement of the a,b,c,d labels in the graphs
		POS = "at graph 0.1,0.95 font ',12'"
		
		set size 1.0,1.0
		set multiplot
		
		set lmargin 0
		set rmargin 0
		set bmargin 3.2
		
		set label 2 'Cumulative Percentage of Occurrences [%]' at graph 2.0,-0.15 center front
		
		# --- GRAPH a
		set label 1 'Seaside-Core' @POS
		@NOXTICS
		set ylabel 'Runtime <= x [s]'
		set origin 0.09,0.0
		set size 0.21,1.0
		plot "../plots/05-Runtime-Seaside.data" using ($4):($1/1000) notitle  w p ls 3, \
		"../plots/05-Runtime-Seaside.data" using ($4):($1/1000) notitle  smooth bezier ls 3
		
		unset label 2
		# --- GRAPH b
		set label 1 'DicThesaurusRex' @POS
		@NOYTICS
		set origin 0.30,0.0
		set size 0.21,1.0
		plot "../plots/05-Runtime-DicThesaurusRex.data" using ($4):($1/1000) notitle  w p ls 3, \
		"../plots/05-Runtime-DicThesaurusRex.data" using ($4):($1/1000) notitle  smooth bezier ls 3
		
		# --- GRAPH c
		set label 1 'SUnit' @POS
		@NOYTICS
		set origin 0.51,0.0
		set size 0.21,1.0
		plot "../plots/05-Runtime-SUnit.data" using ($4):($1/1000) notitle  w p ls 3, \
		"../plots/05-Runtime-SUnit.data" using ($4):($1/1000) notitle  smooth bezier ls 3
		
		# --- GRAPH d
		set border 11 back ls 11
		@NOYTICS
		set ytics mirror
		#set y2range [1:100]
		#set y2tics
		#set logscale y2 10
		set label 1 'Squeak Browser' @POS
		set origin 0.72,0.0
		set size 0.21,1.0
		plot "../plots/05-Runtime-Browser.data" using ($4):($1/1000) notitle  w p ls 3, \
		"../plots/05-Runtime-Browser.data" using ($4):($1/1000) notitle  smooth bezier ls 3
		
		unset multiplot
	\end{gnuplot}
	\caption{Demoplot}
\end{figure}

\paragraph{Threats to Validity}

\subsection{Space Consumption}
\label{s:space-consumption}

\subsection{Threats to Validity}

\section{User Evaluation}
\subsection{Threats to Validity}

\section{Limitations of PathObjects}
\subsection{Collections / Generally: Patterns}
\subsection{Metaprogramming}

\subsection{Reliance on Test Quality} \todo{missing refs}
\label{ss:LimitationsTestQuality}
The best practices for unit testing and the characteristics unit tests should display enjoy broad consent throughout the agile software development community.
To name a few, tests are supposed to be isolated, to be free of side-effects, to run fast, and to be reproducible, automated and unique \cite{meszaros_xunit_2006, beck_test_2002}.
However, when being used as entry points for \textsc{PathObjects}, two of those recommendations become requirements.

Tests that do not run fast basically render our approach useless.
If for instance a test would take 30 seconds to execute, the user not only would have to wait that long before being able to work with our tool, she would also have to wait every time a refinement run has to be performed to collect previously unknown information, like object states or outgoing references.
This would possibly be still acceptable if refinement runs were executed only occasionally, but \textsc{PathObjects} encourages the continuous use of those features.
For example, as depicted in Section \ref{missing}, refinement runs are performed automatically when an object state inspector is expanded.
That means that with every step to another previously unvisited point of time of the execution trace, the underlying test case gets executed automatically, which in turn induces waiting time for the user in the case of long running tests.